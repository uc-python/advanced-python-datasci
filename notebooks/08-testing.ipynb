{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faf6d4e5-0c50-4913-adbc-2abfa1eb6126",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98ce000-52b2-4e17-9ce8-adf66afcfab3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "We've slowly been moving parts of our code into files outside of notebooks... but *why*?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5770ebf-59e6-4aa4-b0b7-0f05a2058959",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- **Reuse** – we could copy `my_module.py` and use it in another project if we had need for the functions in there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf6e7de-bb86-4a70-963a-68ac8182e154",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- **Testability** – one nice aspect of free-standing Python scripts is that we can write tests for them, checking that the functions inside are reliable and bug-free."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58011087-e74a-4561-b203-7da40d759c02",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## The Value of Testing\n",
    "\n",
    "- By running your code on example inputs (for which you know the right output), you can be more confident that it will do what you expect\n",
    "\n",
    "- Since you may reuse code in other projects, it's smart to test on not just the data for the current project, but any inputs that your code might reasonably have to deal with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea80561-432d-469a-a2cc-8280e4e1d558",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "At this point, our directory setup is going to become very important, so let's take a quick detour to talk about it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410baa11-5b62-471c-89f6-15e5fcd659bf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "I'm going to be working with a project that looks something like this:\n",
    "```\n",
    "advanced-python-datasci/\n",
    "├── data/\n",
    "│   ├── adult-census.csv\n",
    "│   ├── ames.csv\n",
    "│   ├── ames_raw.csv\n",
    "│   └── planes.csv\n",
    "└── notebooks/\n",
    "    ├── 01-git.ipynb\n",
    "    ├── 02-explore_data.ipynb\n",
    "    ├── 03-first_model.ipynb\n",
    "    ├── 04-modular_code.ipynb\n",
    "    ├── 05-feat_eng.ipynb\n",
    "    ├── 06-model_eval.ipynb\n",
    "    ├── 07-modularity-pt2.ipynb\n",
    "    ├── 08-testing.ipynb\n",
    "    ├── 09-ml_lifecycle_mgt.ipynb\n",
    "    └── my_module.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1dd113-5a8c-4a1e-934a-a8022941f8bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "What's important:\n",
    "- At the top level, we have folders for `data` and `notebooks`\n",
    "- `my_module.py` is in our notebooks folder\n",
    "\n",
    "Take a few minutes to make sure your project repository is organized similarly. This will make a big difference in this section!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4a73bb-6f7d-4934-81e4-4eaf8c65986f",
   "metadata": {
    "tags": []
   },
   "source": [
    "```\n",
    "advanced-python-datasci/\n",
    "├── data/\n",
    "│   ├── adult-census.csv\n",
    "│   ├── ames.csv\n",
    "│   ├── ames_raw.csv\n",
    "│   └── planes.csv\n",
    "└── notebooks/\n",
    "    ├── 01-git.ipynb\n",
    "    ├── 02-explore_data.ipynb\n",
    "    ├── 03-first_model.ipynb\n",
    "    ├── 04-modular_code.ipynb\n",
    "    ├── 05-feat_eng.ipynb\n",
    "    ├── 06-model_eval.ipynb\n",
    "    ├── 07-modularity-pt2.ipynb\n",
    "    ├── 08-testing.ipynb\n",
    "    ├── 09-ml_lifecycle_mgt.ipynb\n",
    "    └── my_module.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef947385-c387-4ee1-a95e-804e7296c2af",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## A Minimal Test\n",
    "\n",
    "- The easiest way to write a test is in a fresh Python script\n",
    "\n",
    "- Now that our project is organized, we can just create a new file in the `notebooks/` folder, called `tests.py`\n",
    "\n",
    "    - Remember that we can do this in Jupyter with File > New > Text File\n",
    "<br><br>    \n",
    "- Be sure this file appears in your notebooks folder!\n",
    "    - It's very important that it's in the same place as `my_module.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2d2030-7521-4b0c-8f16-59323a5c3794",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Add the following code to your script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92c18669-cc07-44e3-b56d-ae6f2e80f795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_module\n",
    "\n",
    "def test_invocation():\n",
    "    features, target = my_module.get_features_and_target(\n",
    "        csv_file='../data/adult-census.csv',\n",
    "        target_col='class'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf1d7a3-ac3a-4461-804e-86fb5f1538e3",
   "metadata": {},
   "source": [
    "<div class=\"admonition note alert alert-info\">\n",
    "    <b><p class=\"first admonition-title\" style=\"font-weight: bold;\">Discussion</p></b>\n",
    "    If we were to run this code on its own with <code>python tests.py</code>, what would happen?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fd803c-18cc-46f5-9c05-aeae3e44fd3c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Running Our Test\n",
    "- We're going to invoke our test with **pytest**, a tool we'll discuss more shortly\n",
    "- Open a terminal session (in Jupyter, File > New > Terminal)\n",
    "    - Things in the terminal are a bit different here in Windows vs Mac/Linux, so we'll try to help how we can..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b220f1-903e-4e87-915e-b69cc27f7723",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Run the below command in a notebook to find out what folder you're currently working in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eeeb56f0-f89e-4df2-a3a0-5e0c822d03b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/eswan18/Teaching/advanced-python-datasci/notebooks'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5524d865-3db0-421f-a730-2b20190586c9",
   "metadata": {},
   "source": [
    "Copy that result (including the quotes) and in your terminal, paste it after the `cd` command.\n",
    "\n",
    "So in my terminal, I would run:\n",
    "```bash\n",
    "cd '/Users/eswan18/Teaching/advanced-python-datasci/notebooks'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef1e8ba-c980-498b-8d8d-9cb723d469e1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Now...\n",
    "- Windows users: run `dir`\n",
    "- Mac/Linux users: run `ls`\n",
    "\n",
    "This lists the contents of the folder you're currently inside.\n",
    "You should see `my_module.py` and `tests.py` among the output.\n",
    "\n",
    "![ls](images/ls.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b7274f-a733-43e5-96e9-46b5fc26c9c8",
   "metadata": {},
   "source": [
    "Now, we're almost ready to run our test.\n",
    "The only thing left is to set up our terminal so that it's using the same Conda environment as our notebooks -- because `pytest` is installed in that environment.\n",
    "- If you took the intermediate class with us, we discussed Conda and environments in more detail then."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3914bfde-a3e0-4812-830e-c94709b0f7ff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "In the terminal, run\n",
    "```bash\n",
    "conda activate uc-python\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bcd1b7-c0b6-40ca-84d8-1e5579ed694a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "This should add a \"uc-python\" prefix to your terminal prompt:\n",
    "![ls](images/prefix-prompt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8b4577-bce3-4cf6-bfcd-3d37daacadaf",
   "metadata": {
    "tags": []
   },
   "source": [
    "Note that your prompt will look quite a bit different from mine; all that matters is the folder name and the \"uc-python\" prefix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274568fe-5dd9-4545-a204-1db88791b57d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Now we're ready to run our test!\n",
    "\n",
    "In your terminal, type:\n",
    "```bash\n",
    "pytest tests.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14c4a05-10b8-492a-9fd5-8ac26d7ee1fe",
   "metadata": {},
   "source": [
    "You should see some output appear.\n",
    "The last line should look something like:\n",
    "```\n",
    "============ 1 passed in 0.74s ============\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faccf693-ed0b-4fd3-981c-10af87607206",
   "metadata": {},
   "source": [
    "This means that 1 (test) passed and 0 tests failed, and the whole process took 0.74 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c460a17-17ae-4da5-925b-24c16ad687fe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Pytest\n",
    "\n",
    "- Pytest is an automated tool for running sets of tests\n",
    "  - sets of tests are often called test \"suites\"\n",
    "- It expects your tests to be in their own files, and each test needs to be a function\n",
    "  - The name of each function must start with `test_`, so pytest knows it's a test and not just a regular function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecfd6d5-ed3c-4f31-9266-5fe7025a0a43",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Let's look back at our simple test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31aa8a4-edc4-4fa7-9cbd-ea9bd8f4758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_module\n",
    "\n",
    "def test_invocation():\n",
    "    features, target = my_module.get_features_and_target(\n",
    "        csv_file='../data/adult-census.csv',\n",
    "        target_col='class'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7209e5d-2a05-4b5f-8abe-cba67072dcda",
   "metadata": {},
   "source": [
    "Note that our function starts with `def test_`, and pytest is smart enough to run it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd2e226-626c-4fea-b981-9a58b66bf3ef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "What happens if a test fails?\n",
    "Let's add a bad test just to see.\n",
    "\n",
    "Add this function to `tests.py`, below `test_invocation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e546d1e1-975e-4efd-aad1-2aff599e5f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_without_args():\n",
    "    # A test we know will fail because we don't provide arguments\n",
    "    # to the function.\n",
    "    features, target = my_module.get_features_and_target()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d3ea93-1f8c-4c77-a513-7791d113cf5c",
   "metadata": {},
   "source": [
    "Save the file, and then rerun `pytest tests.py` in your terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9804ce-445f-48bc-9517-7cbdcfde4e71",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "============== 1 failed, 1 passed in 0.83s =============="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01a9114-8504-4982-8bd8-837f58839477",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Our original test still passes, but this one fails!\n",
    "\n",
    "Above this line, pytest reports exactly what happened that caused it to fail.\n",
    "We got an error:\n",
    "```text\n",
    "    def test_without_args():\n",
    "        # A test we know will fail because we don't provide arguments\n",
    "        # to the function.\n",
    ">       features, target = my_module.get_features_and_target()\n",
    "\n",
    "E       TypeError: get_features_and_target() missing 2 required positional arguments: 'csv_file' and 'target_col'\n",
    "\n",
    "tests.py:12: TypeError\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd32840e-ad8f-41e4-bb68-7e960d467419",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## What does it mean to \"fail\"?\n",
    "\n",
    "- If a test function encounters any kind of unexpected error, that counts as a failure to pytest\n",
    "- Any test that runs without error \"passes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39977b2c-09f9-4dff-8ca0-5561c45a70e0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Let's remove our `test_without_args` test -- it's not something we actually want to verify about our code.\n",
    "\n",
    "However, one thing we *do* want to check is that the features and target that are returned from our function are a pandas DataFrame and Series, respectively. Let's add a test for that in its place..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07651ef2-dbe0-41df-86c8-ea7a3ca24518",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd # You may want to move this import to the top of the file.\n",
    "\n",
    "def test_return_types():\n",
    "    features, target = my_module.get_features_and_target(\n",
    "        csv_file='../data/adult-census.csv',\n",
    "        target_col='class'\n",
    "    )\n",
    "    assert isinstance(features, pd.DataFrame)\n",
    "    assert isinstance(target, pd.Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8698f939-bb0e-437a-a4dc-0e187a4c901a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "The we can rerun `pytest tests.py`\n",
    "```text\n",
    "=========== 2 passed in 0.88s ===========\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebfc8fa-4394-46e0-aaad-73e114df44fb",
   "metadata": {},
   "source": [
    "Nice! It looks like our function does indeed return a DataFrame and a Series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980a6d26-3306-485a-9acc-ec3f0ed5f2b7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Assert\n",
    "\n",
    "- We used the `assert` keyword to check that `features` was a DataFrame\n",
    "- `assert` is a special Python feature that raises an error if the expression after it isn't True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9d6ee71-8e4b-4999-b40c-8b05c624d794",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 3 - 2 == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d237009-7bc5-4fa6-8c04-22506209ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 100 > 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "faf14df1-233c-478b-95de-a955b21bb15d",
   "metadata": {
    "tags": [
     "ci-skip"
    ]
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j3/v1318ng94fvdpq7kzr0hq9kw0000gn/T/ipykernel_72985/55912000.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 4 * 3 == 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6785b723-dcc9-4086-b206-2e4d0cb39254",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "One common use of `assert` in tests is to check that a variable contains a certain kind of object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56743faa-7b87-46f9-b1a5-fe7cb3e937f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 5\n",
    "assert isinstance(x, int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be034bab-458d-4171-a020-698e2b49ba46",
   "metadata": {
    "tags": [
     "ci-skip"
    ]
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j3/v1318ng94fvdpq7kzr0hq9kw0000gn/T/ipykernel_72985/3799747894.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert isinstance(x, str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ff577f-c12b-4173-98be-03f8a05ebc16",
   "metadata": {},
   "source": [
    "But you can use assert to check any expression in Python that evaluates `True` or `False`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c44769-a2e3-46ef-92f4-ab19d8084638",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "What would happen if we had expected `target` to be a `list` instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ec64358-8087-4140-9ef7-3aed0078b425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_return_types():\n",
    "    features, target = my_module.get_features_and_target(\n",
    "        csv_file='../data/adult-census.csv',\n",
    "        target_col='class'\n",
    "    )\n",
    "    assert isinstance(features, pd.DataFrame)\n",
    "    assert isinstance(target, list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5668c941-3bab-43fe-8244-4153d10f7de2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "![Assert False](images/assert-false.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33a3e97-05c1-467a-9a4f-7c92c2d16db5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "These kinds of tests are handy, because we can make sure our functions return the types of things we expect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dd83ec-ac6b-4ea2-97b3-632cc3a607cb",
   "metadata": {},
   "source": [
    "<div class=\"admonition note alert alert-info\">\n",
    "    <b><p class=\"first admonition-title\" style=\"font-weight: bold;\">Discussion</p></b>\n",
    "    What other aspects of <code>get_features_and_target</code> might we want to test?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068b129f-31f9-4285-b627-c9fc0ee6bf33",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## `test_cols_make_sense`\n",
    "\n",
    "- If `get_features_and_target` works as we expect, the `target` should be a column in the DataFrame, as should *each* of the columns in `features`.\n",
    "- Here's a test to check that.\n",
    "  - There's some pandas functionality in here that we haven't discussed yet, but it should be clear what's happening.\n",
    "- Add this test to `tests.py` at the bottom. Make sure you're importing `pandas` somewhere in the file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7b494430-528a-4d2c-b31d-a95f79803a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cols_make_sense():\n",
    "    features, target = my_module.get_features_and_target(\n",
    "        csv_file='../data/adult-census.csv',\n",
    "        target_col='class'\n",
    "    )\n",
    "    # Load the data ourselves so we can double-check the columns\n",
    "    df = pd.read_csv('../data/adult-census.csv')\n",
    "    assert target.name in df.columns\n",
    "    # Use a list comprehension to check all the feature columns\n",
    "    assert all([feature_col in df.columns for feature_col in features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff541ec-fe8a-4d6d-85a8-3a261ed851ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "```text\n",
    "============= 3 passed in 0.97s =============\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b8dd44-6763-46b1-a7a2-25117f8fe3ad",
   "metadata": {},
   "source": [
    "Whoo!\n",
    "`get_features_and_target` looks pretty reliable;\n",
    "I feel more comfortable using it across modeling projects to load data and split it into a target and a DataFrame of numeric features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745a7d24-d409-431e-96e9-d33b8f7351cf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "If I were planning to use it more, though, there are some other things I might think about testing:\n",
    "- The number of elements in `target` should match the number of rows in the original data, as should the number of rows in `features`.\n",
    "- All of the columns in `features` should be numeric.\n",
    "- All numeric columns in the input file should be present either in `features` or `target`\n",
    "- The name of the `target` series should match the `target_col` argument that we passed into the function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202abf96-24ac-4726-9b40-6836834636b8",
   "metadata": {},
   "source": [
    "But for the sake of time, we're going to stop at these three tests for the function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb04c85-4769-46eb-af95-169d64c0339e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Parametrization\n",
    "- Another way we could check the robustness of `get_features_and_target` is by making sure that it works on multiple data sets, not just the adult census data.\n",
    "- We could write entirely new tests for this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "287234a2-cf40-4df4-a4b0-2d95bce6d522",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_return_types_census():\n",
    "    features, target = my_module.get_features_and_target(\n",
    "        csv_file='../data/adult-census.csv',\n",
    "        target_col='class'\n",
    "    )\n",
    "    assert isinstance(features, pd.DataFrame)\n",
    "    assert isinstance(target, pd.Series)\n",
    "    \n",
    "def test_return_types_ames():\n",
    "    features, target = my_module.get_features_and_target(\n",
    "        csv_file='../data/ames.csv',\n",
    "        target_col='Sale_Price'\n",
    "    )\n",
    "    assert isinstance(features, pd.DataFrame)\n",
    "    assert isinstance(target, pd.Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cf1562-fbba-4a05-b236-4b4891cd4e7a",
   "metadata": {},
   "source": [
    "But this is very duplicative. There has to be a better way!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fec3ffc-a03d-4ec0-b3d4-c4693efb2179",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Indeed, there is: it's **parametrization**.\n",
    "\n",
    "To parametrize a test is to give it multiple inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6c01dac0-6a9c-49e2-9af8-22684a0cc158",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "@pytest.mark.parametrize(\n",
    "    'csv,target',\n",
    "    [\n",
    "        ('../data/adult-census.csv', 'class'),\n",
    "        ('../data/ames.csv', 'Sale_Price')\n",
    "    ]\n",
    ")\n",
    "def test_return_types(csv, target):\n",
    "    features, target = my_module.get_features_and_target(\n",
    "        csv_file=csv,\n",
    "        target_col=target\n",
    "    )\n",
    "    assert isinstance(features, pd.DataFrame)\n",
    "    assert isinstance(target, pd.Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf0ca59-ea2e-4cfe-980f-1f1cb74d70bb",
   "metadata": {},
   "source": [
    "Notice that our inputs are parameters to our test function.\n",
    "`@pytest.mark.parametrize` takes a list of tuples to be passed to our test, along with the arguments they correspond to (`'csv,target'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc51e081-17db-4cef-aa9d-ea64a18854c5",
   "metadata": {},
   "source": [
    "This syntax may look complicated initially, but it's easy enough to copy, paste, and modify for each test you want to parametrize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2277e9-12ac-40ff-b70c-3039ce708bf3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "```text\n",
    "=========== 4 passed in 0.93s ==========\n",
    "```\n",
    "\n",
    "This test should pass, and notice that we went from having 3 tests to 4 -- because one of them is being run twice, once for each parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc2991f-41a8-4fde-b6c0-262322fb9be5",
   "metadata": {},
   "source": [
    "For the sake of time, we're not going to parametrize all of our tests, but in a larger, production-grade test suite, that would be worth doing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a9566c-5fd3-407f-bdc7-1bf18d9821f7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Expecting Exceptions\n",
    "\n",
    "- One mark of good code is that it emits sensible errors\n",
    "\n",
    "- For example, if we pass in the wrong kinds of objects to our function, it should give us an error that points us in the right direction..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b3a2b95-750d-41d0-aaf8-a352e8b9f399",
   "metadata": {
    "tags": [
     "ci-skip"
    ]
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid file path or buffer object type: <class 'list'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j3/v1318ng94fvdpq7kzr0hq9kw0000gn/T/ipykernel_72985/3089255148.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m features, target = my_module.get_features_and_target(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mcsv_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'../data/ames.csv'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# notice that we're passing a list here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtarget_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Sale_Price'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m~/Teaching/advanced-python-datasci/notebooks/my_module.py\u001b[0m in \u001b[0;36mget_features_and_target\u001b[0;34m(csv_file, target_col)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m'''Split a CSV into a DF of numeric features and a target column.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0madult_census\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mraw_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madult_census\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/uc-python/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/uc-python/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/uc-python/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/uc-python/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/uc-python/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/uc-python/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/uc-python/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/uc-python/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0;31m# open URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m     ioargs = _get_filepath_or_buffer(\n\u001b[0m\u001b[1;32m    610\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/uc-python/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Invalid file path or buffer object type: {type(filepath_or_buffer)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     return IOArgs(\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid file path or buffer object type: <class 'list'>"
     ]
    }
   ],
   "source": [
    "features, target = my_module.get_features_and_target(\n",
    "    csv_file=['../data/ames.csv'], # notice that we're passing a list here\n",
    "    target_col='Sale_Price'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a100738-ccc7-499b-990a-4e9d787bb992",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "That error is admittedly long, but it is informative:\n",
    "```python\n",
    "ValueError: Invalid file path or buffer object type: <class 'list'>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12791872-f2da-461b-90b0-43713ce490d4",
   "metadata": {},
   "source": [
    "It might be wise to have a test that makes sure our function raises a `ValueError` on CSV filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "109a7620-f6ed-4ee2-af34-1f8a06a85d5e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize(\n",
    "    'csv', [ ['a', 'b', 'c'], 123 ]\n",
    ")\n",
    "def test_bad_input_error(csv):\n",
    "    with pytest.raises(ValueError):\n",
    "        features, target = my_module.get_features_and_target(\n",
    "            csv_file=csv,\n",
    "            target_col='Sale_Price'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dafd16f-3fa0-4b92-80a1-4b00667564b4",
   "metadata": {},
   "source": [
    "Here, we're testing two types of bad inputs: a list and an integer.\n",
    "Then we're using `with pytest.raises():` -- a *context manager* -- to make sure the code block inside of it raises the error we expect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aca012-4a9b-429a-ae0e-6d6645a5776c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Raising good exceptions may seem unimportant at first glance, but an error is much better than bad input passing silently!\n",
    "That could lead to your project results be invalid.\n",
    "Maybe the output metrics are incorrect, or the model was trained on unreliable data.\n",
    "\n",
    "If something is wrong, you want your code to error as earlier as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb03bdb-cb3f-4681-91c5-eb5b99f2ff2e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Aside: Raising Your Own Exceptions\n",
    "\n",
    "- We don't have time today to go into raising exceptions, but it's possible to issue errors from your own code using `raise`\n",
    "\n",
    "- You might see something like:\n",
    "```python\n",
    "if x < 0:\n",
    "    raise RuntimeError('Invalid value for x')\n",
    "```\n",
    "<br>\n",
    "- This will halt the code in its tracks, propagating a RuntimeError, if `x` is less than 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b4bd75-a465-4aba-86c8-d3a4dbb71e5d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Good Tests\n",
    "\n",
    "- We've written quite a few tests, but what makes a good test? What's worth checking?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770a8dfe-3c22-4a45-8afc-c9293da14cc8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "- Situations\n",
    "  - A very standard set of inputs\n",
    "  - Sets of inputs that are most likely to behave differently than others\n",
    "      - e.g. datasets with lots of NaNs, empty strings, file paths that don't exist\n",
    "- Resulting actions\n",
    "  - Returning valid results\n",
    "  - Raising sensible errors\n",
    "\n",
    "And various permutations of the above -- for **each function** you write."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce0ac3d-80d1-4930-8ae4-dba9f969e6c5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<div class=\"admonition tip alert alert-warning\">\n",
    "    <p class=\"first admonition-title\" style=\"font-weight: bold;\"><b>Your Turn</b></p>\n",
    "<p class=\"last\">Add a test for the <code>make_preprocessor</code> function to <code>tests.py</code>. It can be very simple. Rerun your tests.<br>Then parametrize it and run the tests again.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748bcee6-0993-47d5-aa1e-bd2367efee82",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Wrapping Up\n",
    "- In large projects, there are usually multiple files full of tests.\n",
    "  - Standard practice is to name them all `test_<something>.py` and keep them in a `tests/` folder.\n",
    "  - People have different methods of organizing their tests, but one test file per function of your code is a good starting point.\n",
    "- pytest is extremely powerful and we touched on just a few of its features. I recommend [*Python Testing with Pytest*](https://www.amazon.com/Python-Testing-pytest-Effective-Scalable/dp/1680502409) if you want to learn more.\n",
    "- Learning to write useful tests for your code is a journey. Creating tests is work, and you have to measure the value against the effort required.\n",
    "  - As a general rule, production code justifies many more tests than adhoc analysis projects. Shared code libaries need even more.\n",
    "- You'll hear about various types of tests: unit, integration, smoke, and more.\n",
    "  - The only one to know right now is *unit testing*: tests for small chunks, or units, of your code. That's often the simplest starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094a7336-c502-4261-a106-258faca32915",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<div class=\"admonition tip alert alert-warning\">\n",
    "    <p class=\"first admonition-title\" style=\"font-weight: bold;\"><b>Your Turn</b></p>\n",
    "Add, commit, and push your project updates.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9341be22",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Questions\n",
    "\n",
    "Are there any questions before we move on?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uc-python",
   "language": "python",
   "name": "uc-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
