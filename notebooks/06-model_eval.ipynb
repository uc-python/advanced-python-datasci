{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78c568d7-5364-41dc-b3c8-8275ba0b392c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Model Evaluation & Selection\n",
    "\n",
    "<img src='images/justice-icon.jpg' id=\"logo\" height=\"75%\" width=\"75%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62edfed-c4e6-4253-b75b-bfd1dce995a7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Objective\n",
    "\n",
    "This module is going to introduce you to...\n",
    "\n",
    "1. Cross-validation procedures for more robust model performance assessment.\n",
    "2. Various ways to apply different evaluation metrics.\n",
    "3. Hyperparameter tuning to find optimal model parameter settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd20f1d-1e25-49c0-879f-47583150c8a4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Quick refresher\n",
    "\n",
    "But first, let's review a few things that we learned in the previous modules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54b81a7-1635-412d-b72a-c9262e41a975",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10995d82-7d40-42dd-8118-d356c385ca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages used\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import data\n",
    "adult_census = pd.read_csv('../data/adult-census.csv')\n",
    "\n",
    "# separate feature & target data\n",
    "target = adult_census['class']\n",
    "features = adult_census.drop(columns='class')\n",
    "\n",
    "# drop the duplicated column `\"education-num\"` as stated in the data exploration notebook\n",
    "features = features.drop(columns='education-num')\n",
    "\n",
    "# split into train & test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6483b7ea-7a8e-4859-9cb9-d72c039c4af2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20c9f2dc-40da-4212-9cfd-23fef0feecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages used\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# create selector object based on data type\n",
    "numerical_columns_selector = selector(dtype_exclude=object)\n",
    "categorical_columns_selector = selector(dtype_include=object)\n",
    "\n",
    "# get columns of interest\n",
    "numerical_columns = numerical_columns_selector(features)\n",
    "categorical_columns = categorical_columns_selector(features)\n",
    "\n",
    "# preprocessors to handle numeric and categorical features\n",
    "numerical_preprocessor = StandardScaler()\n",
    "categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "# transformer to associate each of these preprocessors with their respective columns\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('one-hot-encoder', categorical_preprocessor, categorical_columns),\n",
    "    ('standard_scaler', numerical_preprocessor, numerical_columns)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacba690-d95b-4106-8f68-dda2d05b622e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db2eea32-a2c7-4140-a59c-623e123ed11a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8503808041929408"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# packages used\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Pipeline object to chain together modeling processes\n",
    "model = make_pipeline(preprocessor, LogisticRegression(max_iter=500))\n",
    "model\n",
    "\n",
    "# fit our model\n",
    "_ = model.fit(X_train, y_train)\n",
    "\n",
    "# score on test set\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f3a4f0-caf0-480e-8439-d33fab9890b9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Resampling & cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34582129-dd2f-481a-8813-fb80ed5f8090",
   "metadata": {
    "tags": []
   },
   "source": [
    "In our \"03-first_model.ipynb\" notebook we split our data into training and testing sets and we assessed the performance of our model on the test set. Unfortunately, there are a few pitfalls to this approach:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58d9d74-0e75-4c1f-86a9-ec27caf1ac2d",
   "metadata": {},
   "source": [
    "1. If our dataset is small, a single test set may not provide realistic expectations of our model's performance on unseen data.\n",
    "2. A single test set does not provide us any insight on variability of our model's performance.\n",
    "3. Using our test set to drive our model building process can bias our results via _data leakage_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87726e49-4b41-4fc4-ab03-5c3efdfbbdb2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Resampling methods provide an alternative approach by allowing us to repeatedly fit a model of interest to parts of the training data and test its performance on other parts of the training data.\n",
    "\n",
    "<img src='images/resampling.svg' id=\"logo\" height=\"75%\" width=\"75%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ca69ec-1638-4261-9ec0-99708b354560",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "<div class=\"admonition note alert alert-info\">\n",
    "    <p class=\"first admonition-title\" style=\"font-weight: bold;\"><b>Note</b></p>\n",
    "<p class=\"last\">This allows us to train and validate our model entirely on the training data and not touch the test data until we have selected a final \"optimal\" model.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7724614-fef9-402b-bd34-6170d4ac244b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "The two most commonly used resampling methods include ___k-fold cross-validation___ and ___bootstrap sampling___. This module focuses on using k-fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b2af04-02e2-424d-b78c-ae4c6e06d2eb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## K-fold cross-validation\n",
    "\n",
    "Cross-validation consists of repeating the procedure such that the training and testing sets are different each time. Generalization performance metrics are collected for each repetition and then aggregated. As a result we can get an estimate of the variability of the model’s generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bcf456-d4ff-4dd3-8ae1-7aff4e729946",
   "metadata": {
    "tags": []
   },
   "source": [
    "_k_-fold cross-validation (aka _k_-fold CV) is a resampling method that randomly divides the training data into _k_ groups (aka folds) of approximately equal size. \n",
    "\n",
    "![](images/cross_validation_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ffe44c-41d0-49f0-9adc-ffa933262b77",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "The model is fit on $k-1$ folds and then the remaining fold is used to compute model performance.  This procedure is repeated _k_ times; each time, a different fold is treated as the validation set. \n",
    "\n",
    "This process results in _k_ estimates of the generalization error (say $\\epsilon_1, \\epsilon_2, \\dots, \\epsilon_k$). Thus, the _k_-fold CV estimate is computed by averaging the _k_ test errors, providing us with an approximation of the error we might expect on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df80a7ee-686e-4561-8386-6d61f2c9a43f",
   "metadata": {},
   "source": [
    "![](images/cv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f6b1cf-5ba0-4102-8ebb-b1dda1772bf1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "In scikit-learn, the function [`cross_validate`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html) allows us to perform cross-validation and you need to pass it the model, the data, and the target. Since there exists several cross-validation strategies, cross_validate takes a parameter `cv` which defines the splitting strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c3f7ee-49e1-4a3a-be18-7e760380a0d7",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip alert alert-warning\">\n",
    "    <p class=\"first admonition-title\" style=\"font-weight: bold;\"><b>Tip</b></p>\n",
    "    <p class=\"last\">In practice, one typically uses k=5 or k=10. There is no formal rule as to the size of k; however, as k gets larger, the difference between the estimated performance and the true performance to be seen on the test set will decrease.</p>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df17378a-c67f-4177-9ce0-42754c70a750",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.25 s, sys: 56.5 ms, total: 3.3 s\n",
      "Wall time: 3.31 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.61690283, 0.63014293, 0.60851097, 0.66170192, 0.60711718]),\n",
       " 'score_time': array([0.0261631 , 0.02799892, 0.02674103, 0.02812505, 0.02827287]),\n",
       " 'test_score': array([0.85191757, 0.84548185, 0.85790336, 0.85094185, 0.85558286])}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cv_result = cross_validate(model, X_train, y_train, cv=5)\n",
    "cv_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc68f94-850f-492f-9308-bc1b34eb3fe6",
   "metadata": {},
   "source": [
    "The output of cross_validate is a Python dictionary, which by default contains three entries: \n",
    "\n",
    "- `fit_time`: the time to train the model on the training data for each fold, \n",
    "- `score_time`: the time to predict with the model on the testing data for each fold, and \n",
    "- `test_score`: the default score on the testing data for each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ae0bf5c2-e4ea-4140-8def-05b8dee7e77d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean cross-validation accuracy is: 0.852 +/- 0.004\n"
     ]
    }
   ],
   "source": [
    "scores = cv_result[\"test_score\"]\n",
    "print(\"The mean cross-validation accuracy is: \"\n",
    "      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748d0fe6-c5e9-491f-b5da-9c775207fe5f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<div class=\"admonition tip alert alert-warning\">\n",
    "    <p class=\"first admonition-title\" style=\"font-weight: bold;\"><b>Your Turn</b></p>\n",
    "<p class=\"last\">\n",
    "    Using <tt class=\"docutils literal\">KNeighborsClassifier()</tt>, run a 5 fold cross validation procedure and compare the accuracy and standard deviation.  <b>Note</b>: Don't forget to create a new model pipeline object.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53aef758-46e9-4f83-95f9-d33e64b4c0a6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Evaluation metrics\n",
    "\n",
    "* Evaluation metrics allow us to measure the predictive accuracy of our model – the difference between the predicted value ($\\hat{y}_i$) and the actual value ($y_i$).\n",
    "\n",
    "* We often refer to evaluation metrics as ___loss functions___: $f(y_{i} - \\hat{y}_i)$\n",
    "\n",
    "* Scikit-Learn provides multiple ways to compute evaluation metrics and refers to this concept as [___scoring___](https://scikit-learn.org/stable/modules/model_evaluation.html). \n",
    "   1. Estimator scoring method\n",
    "   2. Individual scoring functions\n",
    "   3. Scoring parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1189c888-7b3c-45c5-b669-908dfd9c6eac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Estimator scoring method\n",
    "\n",
    "Every estimator (regression/classification model) has a default scoring method\n",
    "\n",
    "Most classifiers return the mean accuracy of the model on the supplied $X$ and $y$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c7b9e6c-9266-498f-b4a5-47c4486f3a81",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9595782073813708"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# toy data\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X_cancer, y_cancer = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "# fit model\n",
    "clf = LogisticRegression(solver='liblinear').fit(X_cancer, y_cancer)\n",
    "\n",
    "# score \n",
    "clf.score(X_cancer, y_cancer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d861b4a4-b577-4f07-9b89-077b23d945c6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "While most regressors return the $R^2$ metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0f3b0e77-bcd5-4a46-8dc9-b18694bbfd76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7406426641094095"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# toy data\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "X_cali, y_cali = fetch_california_housing(return_X_y=True)\n",
    "\n",
    "# fit model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(X_cali, y_cali)\n",
    "\n",
    "# score\n",
    "reg.score(X_cali, y_cali)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be387d90-b2c3-46ac-abbb-f05a52dfec4a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Individual scoring functions\n",
    "\n",
    "However, these default evaluation metrics are often not the metrics most suitable to the business problem.\n",
    "\n",
    "There are many loss functions to choose from; each with unique characteristics that can be beneficial for certain problems.\n",
    "   * Regression problems\n",
    "      - Mean squared error (MSE)\n",
    "      - Root mean squared error (RMSE)\n",
    "      - Mean absolute error (MAE)\n",
    "      - etc.\n",
    "   * Classification problems\n",
    "      - Area under the curve (AUC)\n",
    "      - Cross-entropy (aka Log loss)\n",
    "      - Precision\n",
    "      - etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927de46b-3dd7-4369-9bbc-86f1035cee12",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Scikit-Learn provides many [scoring functions](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) to choose from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64c4fc90-6c32-42fd-9764-ccec767ce9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f081ff-ab5d-4d53-9dad-cb0ec81d5f1f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "The functions take actual y values and predicted y values -- $f(y_{i} - \\hat{y}_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27c5e12-5c3f-46d1-a5ca-0b9dba406d2e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "__Example regression metrics__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9c411194-11f3-41fb-857f-f8bb37b8c1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.894831181729202"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = reg.predict(X_cali)\n",
    "\n",
    "# Mean squared error\n",
    "metrics.mean_squared_error(y_cali, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bf56419b-38f8-478c-84cb-c53c485f5e52",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1641729880648995"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean absolute percentage error\n",
    "metrics.mean_absolute_percentage_error(y_cali, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c43ac0-7ff6-48c1-b0e2-755aa4bcef8b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "__Example classification metrics__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fb06aa74-86ca-4ed5-bdcf-c4c4e6febd9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9543760900586651"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_cancer)\n",
    "\n",
    "# Area under the curve\n",
    "metrics.roc_auc_score(y_cancer, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf33995d-cd43-4eeb-9f5b-1cfe00db18ac",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.968011126564673"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1 score\n",
    "metrics.f1_score(y_cancer, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5b7b6020-f504-46c4-80cc-77be716d7efb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95       212\n",
      "           1       0.96      0.97      0.97       357\n",
      "\n",
      "    accuracy                           0.96       569\n",
      "   macro avg       0.96      0.95      0.96       569\n",
      "weighted avg       0.96      0.96      0.96       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# multiple metrics at once!\n",
    "print(metrics.classification_report(y_cancer, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a87065-d857-45c7-a964-26396686210f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Scoring parameters\n",
    "\n",
    "And since we prefer to use cross-validation procedures, scikit-learn has incorporated a `scoring` parameter.\n",
    "\n",
    "Most evaluation metrics have a predefined text string that can be supplied as a `scoring` argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b84fc547-1490-4d88-bc0d-681ae559c642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.70541596, 0.71939898, 0.69874835, 0.96958804, 0.72835779]),\n",
       " 'score_time': array([0.031564  , 0.03213   , 0.03276587, 0.04343081, 0.03146601]),\n",
       " 'test_score': array([0.90485472, 0.90326931, 0.91316978, 0.90553186, 0.90816178])}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# say we wanted to use AUC as our loss function while using 5-fold validation\n",
    "cross_validate(model, X_train, y_train, cv=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e63212-f93f-43a5-bf64-e9992f338b57",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<div class=\"admonition note alert alert-info\">\n",
    "    <p class=\"first admonition-title\" style=\"font-weight: bold;\"><b>Note</b></p>\n",
    "    <p class=\"last\">The unified scoring API in scikit-learn always <u>maximizes</u> the score, so metrics which need to be minimized are negated in order for the unified scoring API to work correctly. Consequently, some metrics such as <tt class=\"docutils literal\">mean_squared_error()</tt> will use a predefined text string starting with <b>neg_</b> (i.e. 'neg_mean_squared_error').</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4910e2fb-3713-4237-bb92-f4e126588cb5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00123978, 0.00123715, 0.00064993, 0.00054502, 0.00053811]),\n",
       " 'score_time': array([0.000458  , 0.00037909, 0.00023985, 0.00023079, 0.00022507]),\n",
       " 'test_score': array([-3.52991509, -5.10378498, -5.75101191, -8.9867887 , -5.77179405])}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying mean squared error in a regression k-fold cross validation procedure\n",
    "cross_validate(reg, X_cali, y_cali, cv=5, scoring='neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee71ade-4873-44aa-bea9-8248f0ed9522",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "You can even supply [more than one metric](https://scikit-learn.org/stable/modules/model_evaluation.html#using-multiple-metric-evaluation) or even [define your own custom metric](https://scikit-learn.org/stable/modules/model_evaluation.html#defining-your-scoring-strategy-from-metric-functions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2cc09e79-9b3a-4c28-be5d-6f067b96b276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.67276406, 0.66832423, 0.61833882, 0.63187504, 0.59966493]),\n",
       " 'score_time': array([0.05943894, 0.06058502, 0.05659795, 0.05282521, 0.05487514]),\n",
       " 'test_accuracy': array([0.85191757, 0.84548185, 0.85790336, 0.85094185, 0.85558286]),\n",
       " 'test_roc_auc': array([0.90485472, 0.90326931, 0.91316978, 0.90553186, 0.90816178])}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of supplying more than one metric\n",
    "metrics = ['accuracy', 'roc_auc']\n",
    "\n",
    "cross_validate(model, X_train, y_train, cv=5, scoring=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01df0667-5220-4bd0-a3ca-1bf0429d825e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<div class=\"admonition tip alert alert-warning\">\n",
    "    <p class=\"first admonition-title\" style=\"font-weight: bold;\"><b>Your Turn</b></p>\n",
    "<p class=\"last\">\n",
    "Using the <tt class=\"docutils literal\">KNeighborsClassifier()</tt> from the previous <b>Your Turn</b> exercises, perform a 5 fold cross validation and compute the accuracy <i><u>and</u></i> ROC AUC.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c50870a-37fe-4f79-8fcc-36bea64e0438",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Hyperparameter tuning\n",
    "\n",
    "Given two different models (blue line) to the same data (gray dots), which model do you prefer?\n",
    "\n",
    "A | B\n",
    "- | - \n",
    "![alt](images/modeling-process-bias-model-1.png) | ![alt](images/modeling-process-variance-model-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f91c6b-a72f-4fc5-b3e5-5b15cbc02d58",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Prediction errors can be decomposed into two main subcomponents we care about:\n",
    "\n",
    "- error due to “bias”\n",
    "- error due to “variance”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fc0ec-b19a-41e1-b0bf-340e6c111707",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Bias\n",
    "\n",
    "Error due to ___bias___ is the difference between the expected (or average) prediction of our model and the correct value which we are trying to predict.\n",
    "\n",
    "It measures how far off in general a model’s predictions are from the correct value, which provides a sense of how well a model can conform to the underlying structure of the data.\n",
    "\n",
    "High bias models (i.e. generalized linear models) are rarely affected by the noise introduced by new unseen data\n",
    "\n",
    "![](images/modeling-process-bias-model-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de45ea1-8ec7-4e37-aedc-473801291dd9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Variance\n",
    "\n",
    "Error due to ___variance___ is the variability of a model prediction for a given data point.\n",
    "\n",
    "Many models (e.g., k-nearest neighbor, decision trees, gradient boosting machines) are very adaptable and offer extreme flexibility in the patterns that they can fit to. However, these models offer their own problems as they run the risk of overfitting to the training data. \n",
    "\n",
    "Although you may achieve very good performance on your training data, the model will not automatically generalize well to unseen data.\n",
    "\n",
    "![](images/modeling-process-variance-model-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611edcae-f158-4a5b-8fba-0f22cdf36f14",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "<div class=\"admonition note alert alert-info\">\n",
    "    <p class=\"first admonition-title\" style=\"font-weight: bold;\"><b>Note</b></p>\n",
    "<p class=\"last\">Many high performing models (i.e. random forests, gradient boosting machines, deep learning) are very flexible in the patterns they can conform to due to the many hyperparameters they have. However, this also means they are prone to overfitting (aka can have high variance error).</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa65ab5-793d-4c11-81a1-9fc8a55fad1a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "___Hyperparameters___ (aka tuning parameters) are the \"knobs to twiddle\" to control the complexity of machine learning algorithms and, therefore, the ___bias-variance trade-off___.\n",
    "\n",
    "Some models have very few hyperparameters. For example in a K-nearest neighbor (KNN) model ___K___ (the number of neighbors) is the primary hyperparameter.\n",
    "\n",
    "![](images/modeling-process-knn-options-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b696a78b-9da0-4c1c-8b0e-9c937f6d43b2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "While other models such as gradient boosted machines (GBMs) and deep learning models can have many.\n",
    "\n",
    "___Hyperparameter tuning___ is the process of screening hyperparameter values (or combinations of hyperparameter values) to find a model that balances bias & variance so that the model generalizes well to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c00d09a2-b8b7-4826-b4d6-333633b80760",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.3 s, sys: 8.77 s, total: 57 s\n",
      "Wall time: 57.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'KNN model with 10 neighbors: AUC = 0.883'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# set hyperparameter in KNN model \n",
    "model = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "# create preprocessor & modeling pipeline\n",
    "pipeline = make_pipeline(preprocessor, model)\n",
    "\n",
    "# 5-fold cross validation using AUC error metric\n",
    "results = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "\n",
    "f'KNN model with 10 neighbors: AUC = {np.mean(results):.3f}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ebcec2-7826-4c32-b104-7174e00a506a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "But what if we wanted to assess and compare `n_neighbors` = 5, 10, 15, 20, ... ?\n",
    "\n",
    "For this we could use a ___full cartesian grid search___ using Scikit-Learn's `GridSearchCV()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "47f5852c-0b6c-455b-9495-02c350fc11d9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 577 ms, sys: 466 ms, total: 1.04 s\n",
      "Wall time: 2min 53s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8936630646924394"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# basic model object\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Create grid of hyperparameter values\n",
    "hyper_grid = {'knn__n_neighbors': [5, 10, 15, 20]}\n",
    "\n",
    "# create preprocessor & modeling pipeline\n",
    "pipeline = Pipeline([('prep', preprocessor), ('knn', knn)])\n",
    "\n",
    "# Tune a knn model using grid search\n",
    "grid_search = GridSearchCV(pipeline, hyper_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "results = grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model's cross validated AUC\n",
    "abs(results.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991f78e0-8a3b-4e7c-8d3d-b491ce8e2704",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<div class=\"admonition tip alert alert-warning\">\n",
    "    <p class=\"first admonition-title\" style=\"font-weight: bold;\"><b>Tip</b></p>\n",
    "    <p class=\"last\">We use <tt class=\"docutils literal\">Pipeline</tt> rather than <tt class=\"docutils literal\">make_pipeline</tt> in the above because it allows us to name the different steps in the pipeline. This allows us to assign hyperparameters to distinct steps within the pipeline.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "901e41c8-3879-4a7d-a857-9e76a9c027f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knn__n_neighbors': 20}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13b4426-e2e6-48cc-bfa9-68e3e0d350ce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "However, a cartesian grid-search approach has limitations. \n",
    "\n",
    "* It does not scale well when the number of parameters to tune is increasing.\n",
    "* It also forces regularity rather than aligning values assessed to distributions.\n",
    "\n",
    "![](images/random_search.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81759df6-c076-4f4e-a9ae-aa21fa8409a9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<div class=\"admonition note alert alert-info\">\n",
    "    <p class=\"first admonition-title\" style=\"font-weight: bold;\"><b>Note</b></p>\n",
    "    <p class=\"last\">Random search based on hyperparameter distributions has proven to perform as well, if not better than, standard grid search. Learn more <a href=\"http://jmlr.csail.mit.edu/papers/volume13/bergstra12a/bergstra12a.pdf\">here</a>.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01aaa36-aa18-4df5-a3e3-53f26bda987a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "For example, say we want to train a random forest classifier. Random forests are very flexible algorithms and can have _several_ hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8bb732f9-02d6-4ff3-a520-dd5a4e0d6fe9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# basic model object\n",
    "rf = RandomForestClassifier(random_state=123)\n",
    "\n",
    "# create preprocessor & modeling pipeline\n",
    "pipeline = Pipeline([('prep', preprocessor), ('rf', rf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e309ea66-0b43-458b-af83-e3cbb5c23145",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "For this particular random forest algorithm we'll assess the following hyperparameters. Don't worry if you are not familiar with what these do.\n",
    "\n",
    "* `n_estimators`: number of trees in the forest,\n",
    "* `max_features`: number of features to consider when looking for the best split,\n",
    "* `max_depth`: maximum depth of each tree built,\n",
    "* `min_samples_leaf`: minimum number of samples required in a leaf node,\n",
    "* `max_samples`: number of samples to draw from our training data to train each tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42873c2c-0ca1-4778-99b9-5fbee7ca008e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "A standard grid search would be very computationally intense.\n",
    "\n",
    "Instead, we'll use a random latin hypercube search using [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html).\n",
    "\n",
    "To build our grid, we need to specify distributions for our hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012770ff-f71f-42b0-b2d1-2c7be30d7223",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "<div class=\"admonition tip alert alert-warning\">\n",
    "    <p class=\"first admonition-title\" style=\"font-weight: bold;\"><b>Tip</b></p>\n",
    "    <p class=\"last\"><tt class=\"docutils literal\">scipy.stats.loguniform</tt> can be used to generate floating numbers. To generate random values for integer-valued parameters (e.g. <tt class=\"docutils literal\">min_samples_leaf</tt>) we can adapt is as follows:</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "64dbdb5b-8343-492e-8fc4-47e4afa2b087",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import loguniform\n",
    "\n",
    "\n",
    "class loguniform_int:\n",
    "    \"\"\"Integer valued version of the log-uniform distribution\"\"\"\n",
    "    def __init__(self, a, b):\n",
    "        self._distribution = loguniform(a, b)\n",
    "\n",
    "    def rvs(self, *args, **kwargs):\n",
    "        \"\"\"Random variable sample\"\"\"\n",
    "        return self._distribution.rvs(*args, **kwargs).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eabb636b-f9b3-420b-b1de-d7e602bc2c37",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# specify hyperparameter distributions to randomly sample from\n",
    "param_distributions = {\n",
    "    'rf__n_estimators': loguniform_int(50, 1000),\n",
    "    'rf__max_features': loguniform(.1, .5),\n",
    "    'rf__max_depth': loguniform_int(4, 20),\n",
    "    'rf__min_samples_leaf': loguniform_int(1, 100),\n",
    "    'rf__max_samples': loguniform(.5, 1),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735f7ef1-b091-4031-aeb9-d24d48ee2eaf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Now, we can define the randomized search using the different distributions. \n",
    "\n",
    "Executing 10 iterations of 5-fold cross-validation for random parametrizations of this model on this dataset can take from 10 seconds to several minutes, depending on the speed of the host computer and the number of available processors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1f9599bb-70d7-4c0b-aaae-e78e9a9a582a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "CPU times: user 19.2 s, sys: 351 ms, total: 19.5 s\n",
      "Wall time: 3min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# perform 10 random iterations\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline, \n",
    "    param_distributions=param_distributions, \n",
    "    n_iter=10,\n",
    "    cv=5, \n",
    "    scoring='roc_auc',\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "results = random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5d2a6782-045b-43f9-8d69-89db52ea1e6f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9167993399776069"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a3985bf7-2fdc-4d4a-a929-dcc297a0ac6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rf__max_depth': 19,\n",
       " 'rf__max_features': 0.4440733300753526,\n",
       " 'rf__max_samples': 0.9487528482967953,\n",
       " 'rf__min_samples_leaf': 4,\n",
       " 'rf__n_estimators': 66}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d1777a-2aa3-41db-8060-098b6707a791",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Wrapping up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fddb05-585f-4ec6-9cb5-7827183e7df5",
   "metadata": {},
   "source": [
    "This module discussed:\n",
    "\n",
    "1. How to use `cross_validate` to perform _k_-fold cross-validation procedures.\n",
    "2. The three different ways to apply different evaluation metrics:\n",
    "   a. Default estimator score method - `estimator.score()`\n",
    "   b. Individual scoring functions - `from sklearn import metrics`\n",
    "   c. Scoring parameters - `cross_validate(..., scoring='roc_auc')`\n",
    "3. How to use `GridSearchCV` and `RandomizedSearchCV` to perform hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e0bd02-663b-4edf-8386-fa9fd2ddacd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
