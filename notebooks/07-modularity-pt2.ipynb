{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd9d2e0d-6b11-454d-a3e4-3e6bdf6af479",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Modular Code, Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc36274-6ff4-430d-bd49-a8054cd7625e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "- In our coverage of modular code, we talked about abstracting reusable code chunks into their own **functions**\n",
    "    - And, in turn, grouping those functions together into separate **modules**\n",
    "    - We created a function that splits a data set into its features (a DataFrame) and target (a Series)\n",
    "    \n",
    "- In our discussion of feature engineering, we showed how one might make a \"preprocessor\": a column transformer that one-hot encodes categorical features and applies standard scaling to numeric columns\n",
    "    - We then chained this preprocessor together with a logistic regression model in order to form a scikit-learn **pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2874f42-6c62-4228-bee3-952a11414532",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- We might use the same approach in preprocessing other datasets, so **let's move that logic to its own function and add it to our personal module**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238ba661-113d-44e8-8828-0530eba34a34",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Writing a Preprocessor Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84276dd0-5d1c-4991-86a3-3d3c6f32f8b5",
   "metadata": {},
   "source": [
    "Sometimes it's easiest to write a function's definition, or *signature*, before actually writing its code.\n",
    "\n",
    "Our function is going to give us a column transformer that we can use in pipelines.\n",
    "The only parameter will be the features DataFrame (at least, for right now)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bfc1a8-4fa8-4b44-adba-518baae1c4f7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "One possible function signature looks like this:\n",
    "\n",
    "```python\n",
    "def make_preprocessor(features):\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65503a5-a248-4f0a-914e-70bb2985143c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Now that we have our definition, we can add code to it.\n",
    "In this case, we can reuse the code we wrote in the feature engineering section.\n",
    "\n",
    "```python\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('one-hot-encoder', categorical_preprocessor, categorical_columns),\n",
    "    ('standard_scaler', numeric_preprocessor, numeric_columns)\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1be5273-c16b-4de4-92e1-f1ddf1ca2faa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Can we just put all of that code into our function without any changes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92be057e-57d5-405d-91f1-d1419c03e6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preprocessor(features):\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('one-hot-encoder', categorical_preprocessor, categorical_columns),\n",
    "        ('standard_scaler', numeric_preprocessor, numeric_columns)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99da5b7-bc3b-4401-924f-d1f2fe5af86b",
   "metadata": {},
   "source": [
    "<div class=\"admonition note alert alert-info\">\n",
    "    <b><p class=\"first admonition-title\" style=\"font-weight: bold;\">Discussion</p></b>\n",
    "    Does anyone see any issues with this?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "218afb3f-cf49-4f1c-8fb7-c21367888811",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fake_features = pd.read_csv('../data/planes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deb5e1d0-e198-4d47-9dd5-773a56219005",
   "metadata": {
    "tags": [
     "ci-skip"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'categorical_preprocessor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9w/9m3mzyd96fbdm8q4sy2pjpdw0000gn/T/ipykernel_61981/3965947682.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_preprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/9w/9m3mzyd96fbdm8q4sy2pjpdw0000gn/T/ipykernel_61981/2727407406.py\u001b[0m in \u001b[0;36mmake_preprocessor\u001b[0;34m(features)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     preprocessor = ColumnTransformer([\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0;34m'one-hot-encoder'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_preprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;34m'standard_scaler'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_preprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     ])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'categorical_preprocessor' is not defined"
     ]
    }
   ],
   "source": [
    "preprocessor = make_preprocessor(fake_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c517343b-3883-49e7-8beb-929c2bcc2a00",
   "metadata": {},
   "source": [
    "Our code is missing some context.\n",
    "`categorical_preprocessor`, `categorical_columns`, `numeric_preprocessor`, and `numeric_columns` aren't defined yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d8e82a-3f3d-4ec4-9633-f10b41067760",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Here's an updated version in which we assign to those variables before using them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "405b65a4-fd13-490b-b713-cde9e8243b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preprocessor(features):\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "    \n",
    "    categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "    numeric_preprocessor = StandardScaler()\n",
    "    \n",
    "    numeric_columns = features.select_dtypes(exclude=object).columns\n",
    "    categorical_columns = features.select_dtypes(include=object).columns\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('one-hot-encoder', categorical_preprocessor, categorical_columns),\n",
    "        ('standard_scaler', numeric_preprocessor, numeric_columns)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804f7c2e-e468-4886-96f2-f845c60c189b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Things run without error now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9c97464-cb3b-47f1-a721-8e256e1dfda7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessor = make_preprocessor(fake_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efbec89-5229-437d-abc3-412911d5ff7f",
   "metadata": {},
   "source": [
    "But there are a couple of other issues.\n",
    "\n",
    "What does our resulting preprocessor object look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1cda4d1-0cd3-4c96-abab-6485a80ae77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4a2f7bb-0302-45ff-9686-bdcba63e3ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340778e2-cb1e-4e85-95a3-d9c670842050",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "- We need to remember to *return a value* -- otherwise we can't get anything useful out of the function.\n",
    "\n",
    "- Generally, Python best practice is to import libraries *outside* functions.\n",
    "All imports, even if they're to be used in different functions, are usually placed at the top of the Python module.\n",
    "\n",
    "Let's make those changes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85c223b7-b181-49f8-ad3b-982a3a8b4577",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "def make_preprocessor(features):\n",
    "    categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "    numeric_preprocessor = StandardScaler()\n",
    "    \n",
    "    numeric_columns = features.select_dtypes(exclude=object).columns\n",
    "    categorical_columns = features.select_dtypes(include=object).columns\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('one-hot-encoder', categorical_preprocessor, categorical_columns),\n",
    "        ('standard_scaler', numeric_preprocessor, numeric_columns)\n",
    "    ])\n",
    "    \n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2968aae-f721-4e3b-bd82-848075421116",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "And then make sure it works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78249c2c-e50f-469a-9b40-9037e922cb33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('one-hot-encoder',\n",
       "                                 OneHotEncoder(handle_unknown='ignore'),\n",
       "                                 Index(['tailnum', 'type', 'manufacturer', 'model', 'engine'], dtype='object')),\n",
       "                                ('standard_scaler', StandardScaler(),\n",
       "                                 Index(['year', 'engines', 'seats', 'speed'], dtype='object'))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = make_preprocessor(fake_features)\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3655b1f9-63b9-4d3b-b60a-9b779b02d784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.compose._column_transformer.ColumnTransformer"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087548dc-5a61-442f-bbc8-88291b377bf9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Now that our function is ready, we can add it to our module!\n",
    "Reopen `my_module.py` and add our imports to the top and our new function at the end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11c199c1-b22b-455d-8a97-56cb8c4f04ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "def get_features_and_target(csv_file, target_col):\n",
    "    '''Split a CSV into a DF of numeric features and a target column.'''\n",
    "    \n",
    "    adult_census = pd.read_csv(csv_file)\n",
    "    \n",
    "    raw_features = adult_census.drop(columns=target_col)\n",
    "    numeric_features = raw_features.select_dtypes(np.number)\n",
    "    feature_cols = numeric_features.columns.values\n",
    "\n",
    "    features = adult_census[feature_cols]\n",
    "    target = adult_census[target_col]\n",
    "    \n",
    "    return (features, target)\n",
    "\n",
    "def make_preprocessor(features):\n",
    "    '''Create a column transformer that applies sensible preprocessing procedures.'''\n",
    "    categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "    numeric_preprocessor = StandardScaler()\n",
    "    \n",
    "    numeric_columns = features.select_dtypes(exclude=object).columns\n",
    "    categorical_columns = features.select_dtypes(include=object).columns\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('one-hot-encoder', categorical_preprocessor, categorical_columns),\n",
    "        ('standard_scaler', numeric_preprocessor, numeric_columns)\n",
    "    ])\n",
    "    \n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029f3248-ef60-4159-944b-66f9feb17d9a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Our functions can work together now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25688ca6-8c11-4a26-b03e-363ad8f4d6d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import my_module\n",
    "\n",
    "features, target = my_module.get_features_and_target(\n",
    "    csv_file='../data/adult-census.csv',\n",
    "    target_col='class',\n",
    ")\n",
    "\n",
    "# Drop education-num as discussed before, because it's redundant.\n",
    "features = features.drop('education-num', axis=1)\n",
    "\n",
    "preprocessor = my_module.make_preprocessor(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfd9dab-40c9-4bff-9bec-2a02107c82a5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "And we could make this preprocessor part of a scikit-learn pipeline, as we saw before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "251aeca0-0c7c-4b67-aa7e-3171143fac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# If we want a logistic regression\n",
    "model = make_pipeline(preprocessor, LogisticRegression())\n",
    "# or perhaps we prefer a random forest?\n",
    "#model = make_pipeline(RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2a02e4-1b72-4c92-97f9-eba814588ee4",
   "metadata": {},
   "source": [
    "If we were even more ambitious, we could build a function that just took `features` and a model class (such as `LogisticRegression`) and returned a pipeline.\n",
    "But that wouldn't simplify things much beyond what we already have, so we'll leave that as an exercise you can try if you want to experiment more with modularizing your code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e4cb31-5a7e-464b-b158-eca91589c612",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "We can use our pipeline on real data, just as we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f64a285-d1af-443d-8c85-8df5c45db02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7988698714274015"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# one small addition: the target column is encoded as a string in our data so we need to convert to 1s and 0s.\n",
    "target = target.str.contains('>50K').astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=123)\n",
    "\n",
    "# fit our model\n",
    "_ = model.fit(X_train, y_train)\n",
    "\n",
    "# score on test set\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be669d43-e908-4489-9478-a7862c36baf0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<div class=\"admonition note alert alert-info\">\n",
    "    <b><p class=\"first admonition-title\" style=\"font-weight: bold;\">Discussion</p></b>\n",
    "    What if we wanted to make our function more flexible, such that users could determine what kind of categorical and numeric encoding schemes should be used?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f78f15e-a6dc-407d-baf5-51ff5f860bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preprocessor(features):\n",
    "    '''Create a column transformer that applies sensible preprocessing procedures.'''\n",
    "    categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "    numeric_preprocessor = StandardScaler()\n",
    "    numeric_columns = features.select_dtypes(exclude=object).columns\n",
    "    categorical_columns = features.select_dtypes(include=object).columns\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('one-hot-encoder', categorical_preprocessor, categorical_columns),\n",
    "        ('standard_scaler', numeric_preprocessor, numeric_columns)\n",
    "    ])\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e0a838-69c5-45dd-b2bd-93eea82983ae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "One approach would be to add \"categorical_preprocessor\" and \"numeric_preprocessor\" parameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87c46182-6c3e-4c86-bcac-267ae75bb034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preprocessor(features, categorical_preprocessor, numeric_preprocessor):\n",
    "    '''Create a column transformer that applies sensible preprocessing procedures.'''\n",
    "    numeric_columns = features.select_dtypes(exclude=object).columns\n",
    "    categorical_columns = features.select_dtypes(include=object).columns\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('one-hot-encoder', categorical_preprocessor, categorical_columns),\n",
    "        ('standard_scaler', numeric_preprocessor, numeric_columns)\n",
    "    ])\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6da51b-913f-4f23-83bb-a56fdc901c08",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "This allows us to specify the precise transformations we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18560d32-557b-499c-8ea2-8b77375727e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will work the same as the original\n",
    "preprocessor = make_preprocessor(\n",
    "    fake_features,\n",
    "    categorical_preprocessor=OneHotEncoder(handle_unknown=\"ignore\"),\n",
    "    numeric_preprocessor=StandardScaler(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5684fea7-0154-4685-84f9-898ff2ec5abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer, OrdinalEncoder\n",
    "# Uses different strategies\n",
    "preprocessor = make_preprocessor(\n",
    "    fake_features,\n",
    "    categorical_preprocessor=OrdinalEncoder(),\n",
    "    numeric_preprocessor=Normalizer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a296ab1-b132-4626-bd6a-df4769a81414",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "But this is a bit cumbersome - we have to specify all three arguments every time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1eb74ab-40b3-4876-b509-b76f74751272",
   "metadata": {
    "tags": [
     "ci-skip"
    ]
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "make_preprocessor() missing 2 required positional arguments: 'categorical_preprocessor' and 'numeric_preprocessor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9w/9m3mzyd96fbdm8q4sy2pjpdw0000gn/T/ipykernel_61981/3965947682.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_preprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: make_preprocessor() missing 2 required positional arguments: 'categorical_preprocessor' and 'numeric_preprocessor'"
     ]
    }
   ],
   "source": [
    "preprocessor = make_preprocessor(fake_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b511487-1e15-450e-a988-65fbb95cea27",
   "metadata": {},
   "source": [
    "It would be nicer if these arguments were optional, and *defaulted* to the original choices..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0ba98d6-2911-4f21-9d45-dcbc1ee420f7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_preprocessor(features, categorical_preprocessor=None, numeric_preprocessor=None):\n",
    "    '''Create a column transformer that applies sensible preprocessing procedures.'''\n",
    "    \n",
    "    if categorical_preprocessor is None:\n",
    "        categorical_preprocessor = OneHotEncoder(handle_unknown='ignore')\n",
    "    if numeric_preprocessor is None:\n",
    "        numeric_preprocessor = StandardScaler()\n",
    "        \n",
    "    numeric_columns = features.select_dtypes(exclude=object).columns\n",
    "    categorical_columns = features.select_dtypes(include=object).columns\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('one-hot-encoder', categorical_preprocessor, categorical_columns),\n",
    "        ('standard_scaler', numeric_preprocessor, numeric_columns)\n",
    "    ])\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1618821-d5ba-40f8-b5b7-832cc5cf3d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_preprocessor(fake_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a0d4a7-ee7b-4eec-a908-9905a96dd32d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<div class=\"admonition tip alert alert-warning\">\n",
    "    <p class=\"first admonition-title\" style=\"font-weight: bold;\"><b>Your Turn</b></p>\n",
    "<p class=\"last\">Update your <code>my_module.py</code> file to reflect the changes we made above. Try testing out the new version with the below code:</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc23b739-d556-4eae-a306-36ad463eb8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7806076488412087"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import my_module\n",
    "\n",
    "features, target = my_module.get_features_and_target(\n",
    "    csv_file='../data/adult-census.csv',\n",
    "    target_col='class',\n",
    ")\n",
    "features = features.drop('education-num', axis=1)\n",
    "target = target.str.contains('>50K').astype(int)\n",
    "\n",
    "preprocessor = my_module.make_preprocessor(features, numeric_preprocessor=Normalizer())\n",
    "model = make_pipeline(preprocessor, LogisticRegression())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=123)\n",
    "\n",
    "_ = model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af64ffd4-6437-4cd3-a9fa-5beaf52a427a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Remember GitHub?\n",
    "\n",
    "We always commit signicant code updates to GitHub, so let's stop now and push our changes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uc-python",
   "language": "python",
   "name": "uc-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
